struct CSR {
    N : u32, //cols
    M : u32, //rows
    nnz : u32, //number of nonzero elements
    values : &mut[f32], //row-major
    cols : &mut[u32],
    row_index : &mut[u32]
}



struct Semiring {
    zero : fn() -> f32,
    one : fn() -> f32,
    plus : fn(f32,f32) -> f32,
    multiply : fn(f32,f32) -> f32
}


struct Matrix {
    semiring : Semiring,
    get : fn (u32, u32) -> f32,
    release : fn() -> (),//  get, release, semiring ..., multiply
    multiply : fn(Matrix) -> Matrix
}

//read matrix
// turn on suitesparse

//Won't work fow now
// trait<T> Semiring{
    // fn zero() -> T,
    // fn one() -> T,
    // fn plus(T,T) -> T,
    // fn multiply(T,T) ->T
// }

// impl Semiring[float] ...
// Matrix[Semiring] ...



//decompose

//multiply simple
//multiply

//preprosess rows
extern "C" {
    fn prefixSum(start : &mut[u32],end : u32) -> ();
}
//prefix sum
//spGemm

extern fn get_nnz(cst : &CSR) -> u32 {
    (*cst).nnz
}

fn copy_csr_toDevice(source : &CSR, dst : &CSR) -> () {
    runtime_copy(runtime_device(0, 0), source.values as &[i8], 0i64, runtime_device(1, 0), dst.values as &[i8], 0i64, dst.nnz as i64 * sizeof[f32]());
    runtime_copy(runtime_device(0, 0), source.cols as &[i8], 0i64, runtime_device(1, 0), dst.cols as &[i8], 0i64, dst.nnz as i64 * sizeof[f32]());
    runtime_copy(runtime_device(0, 0), source.row_index as &[i8], 0i64, runtime_device(1, 0), dst.row_index as &[i8], 0i64, (dst.M + 1u32) as i64 * sizeof[u32]());
    
}

fn release_csr_Device(csr : &CSR)-> () {
    runtime_release(runtime_device(1, 0), csr.values as &[i8]);
    runtime_release(runtime_device(1, 0), csr.cols as &[i8]);
    runtime_release(runtime_device(1, 0), csr.row_index as &[i8]);
    
}

fn release_csr_Host(csr : &CSR)-> () {
    runtime_release(runtime_device(0, 0), csr.values as &[i8]);
    runtime_release(runtime_device(0, 0), csr.cols as &[i8]);
    runtime_release(runtime_device(0, 0), csr.row_index as &[i8]);
    
}

fn copy_csr_toHost(source : &CSR, dst : &CSR) -> (){
    runtime_copy(runtime_device(1, 0), source.values as &[i8], 0i64, runtime_device(0, 0), dst.values as &[i8], 0i64, dst.nnz as i64 * sizeof[f32]());
    runtime_copy(runtime_device(1, 0), source.cols as &[i8], 0i64, runtime_device(0, 0), dst.cols as &[i8], 0i64, dst.nnz as i64 * sizeof[f32]());
    runtime_copy(runtime_device(1, 0), source.row_index as &[i8], 0i64, runtime_device(0, 0), dst.row_index as &[i8], 0i64, (dst.M + 1u32) as i64 * sizeof[u32]());
}

fn getThreadId() -> i32 {
    let blockId = cuda_blockIdx_y() * cuda_gridDim_x() + cuda_blockIdx_x();
    let threadId = blockId * cuda_blockDim_x() + cuda_threadIdx_x();
    return(threadId)
}

fn minimum(l : u32, r : u32) -> u32{
    if r == 0u32{ 
        return(l)
    }
    else if l == 0u32 { 
        return(r)
    }
    else {
        if l < r {
            return(l)
        }
        else { 
            return(r)
        }
    }
}

//works fine
fn WarpMin(mask : u32, value : u32) -> u32{
    let mut offset = 16u32;
    let mut tmp_val = value;
    while (offset > 0u32) {
        tmp_val = minimum(tmp_val, cuda_warp_shfl_up_u32(mask, tmp_val, offset, 32));
        offset = offset / 2u32;
    }
    return (tmp_val)
}


fn WarpBinOpShared(sData : &mut[3][f32], laneId : u32, lastLaneId : u32) -> f32{

    let mut offset = 16u32;
    if laneId <= lastLaneId {
        while (offset > 0u32) {
            if offset <= laneId {sData(laneId) = sData(laneId) + sData(laneId - offset)};
            cuda_syncthreads();
            offset = offset / 2u32;
        }

    }
    sData(lastLaneId)
}

//should be generic and replaceable 
fn WarpBinOp(mask : u32, value : f32, binOp : fn(f32,f32) -> f32, zero : fn() -> f32, laneId : u32) -> f32 {
    let mut offset = 16u32;
    let mut tmp_val = value;
    while (offset > 0u32) {
        //think about reduction??
        let mut shfl = cuda_warp_shfl_up_f32(mask, tmp_val, offset, 32);
        if offset > laneId {
            shfl = zero();
        }
        tmp_val = binOp(tmp_val,shfl);//tmp_val + cuda_warp_shfl_down_f32(mask, tmp_val, offset, 32);
        offset = offset / 2u32;
    }
    return (tmp_val)
}




fn WarpSum(mask : u32, value : f32, laneId : u32) -> f32 {
    let mut offset = 16u32;
    let mut tmp_val = value;
    while (offset > 0u32) {
        //think about reduction??
        let mut shfl = cuda_warp_shfl_up_f32(mask, tmp_val, offset, 32);
        if offset > laneId {
            shfl = 0.0f32;
        }
        tmp_val = tmp_val + shfl;
        offset = offset / 2u32;
    }
    return (tmp_val)
}



fn preprosessRows(a : CSR, b : CSR, cRows : &mut[u32]) -> () {
    
    let mut grid = (1,1,1);
    let block = (32,1,1);

    let k = (a.M / 65535u32) + 1u32;


    if k > 1u32 {
        grid(0) = 65535;
        if k > 65535u32 {
            grid(1) = 65535;
        } else {
            grid(1) = k as i32;
        }
    } else {
        grid(0) = a.M as i32;
    }
    

    grid(0) = grid(0) * block(0);
    
    with cuda(0,grid,block) {
        let full_mask : u32 = 0xffffffffu32;

        let threadId = getThreadId();

        let warpId = threadId / 32; //threadId / 32;
        let laneId = cuda_threadIdx_x() as u32 % 32u32;

        if warpId as u32 < a.M {


            let aStart = a.row_index(warpId);
            let aEnd = a.row_index(warpId + 1);

            

            // let mut mask : u32 = 0u32;

            let mut tmp = 0u32;

            let mask_flag = if aStart + laneId < aEnd {1} else {0};
            let mask = cuda_warp_sync_vote(full_mask, mask_flag); //0 if the row is empty

            if aStart + laneId < aEnd {
                let bRowId = a.cols(aStart + laneId);
                

                let mut rowPos = b.row_index(bRowId);
                
                let mut while_flag = if rowPos < b.row_index(bRowId + 1u32) {1} else {0};

                let mut while_loop = cuda_warp_sync_any(mask, while_flag) == 1;
                
                while (while_loop) {
                    let front_col = if rowPos < b.row_index(bRowId + 1u32) {b.cols(rowPos) + 1u32} else {0u32};

                    let mut frontColMin = WarpMin(mask,front_col);
                    frontColMin = cuda_warp_shfl_u32(mask, frontColMin, cuda_popc_u32(mask) - 1, 32);
                    
                    if front_col == frontColMin {
                        rowPos = rowPos + 1u32;
                    
                    }
                    tmp = tmp + 1u32;
                    while_flag = if rowPos < b.row_index(bRowId + 1u32) {1} else {0};
                    while_loop = cuda_warp_sync_any(mask, while_flag) == 1;
                }

                
            }
            if laneId == 0u32 {
                if mask == 0u32 { //empty row
                    cRows(warpId + 1) = 0u32;
                } else {
                    cRows(warpId as i32 + 1) = tmp;    
                }
            }
        }
    }

    synchronize_cuda(0);


}


fn spGEMMimpala_device(a : CSR, b : CSR, c : CSR) -> () {
    
    let mut grid = (1,1,1);
    let block = (32,1,1);

    let k = (a.M / 65535u32) + 1u32;

    if k > 1u32 {
        grid(0) = 65535;
        if k > 65535u32 {
            grid(1) = 65535;
        } else {
            grid(1) = k as i32;
        }
    } else {
        grid(0) = a.M as i32;
    }

    grid(0) = grid(0) * block(0);
    
    with cuda(0,grid,block) {
        let full_mask : u32 = 0xffffffffu32;

        let sData = reserve_shared[f32](32);

        let threadId = getThreadId();

        let warpId = threadId / 32; //threadId / 32;
        let laneId = cuda_threadIdx_x() as u32 % 32u32;

        if warpId as u32 < a.M {


            let aStart = a.row_index(warpId);
            let aEnd = a.row_index(warpId + 1);

            

            // let mut mask : u32 = 0u32;

            let mut tmp = 0.0f32;

            let mask_flag = if aStart + laneId < aEnd {1} else {0};
            let mask = cuda_warp_sync_vote(full_mask, mask_flag); //0 if the row is empty

            if aStart + laneId < aEnd {
                let bRowId = a.cols(aStart + laneId);

                let row_weight = a.values(aStart + laneId);
                

                let mut rowPos = b.row_index(bRowId);
                
                let mut while_flag = if rowPos < b.row_index(bRowId + 1u32) {1} else {0};

                let mut while_loop = cuda_warp_sync_any(mask, while_flag) == 1;
                
                let mut currentCol = 0u32;

                while (while_loop) {
                    // cuda_vprintf("asdv\n%u32","laneId");
                    let front_col = if rowPos < b.row_index(bRowId + 1u32) {b.cols(rowPos) + 1u32} else {0u32};
                    let front_val = if rowPos < b.row_index(bRowId + 1u32) {b.values(rowPos)} else {0.0f32};

                    let mut frontColMin = WarpMin(mask,front_col);
                    frontColMin = cuda_warp_shfl_u32(mask, frontColMin, cuda_popc_u32(mask) - 1, 32);
                    
                    if front_col == frontColMin {
                        rowPos = rowPos + 1u32;
                        tmp = front_val * row_weight; //todo semiring
                        sData(laneId) = tmp;
                        // tmp = front_val + row_weight;
                    
                    } else {
                        tmp = 0.0f32;
                        sData(laneId) = tmp;
                    }

                    cuda_syncthreads();
                    // let mut sum = WarpSum(mask,tmp,laneId);
                    // let mut sum = WarpBinOp(mask,tmp,|x : f32, y : f32| x + y, || 0.0f32, laneId);
                    // let mut sum = WarpBinOp(mask,tmp,|x : f32, y : f32| if x > y {x} else {y}, || 1.175494e-37f32, laneId);
                    // sum = cuda_warp_shfl_f32(mask, sum, cuda_popc_u32(mask) - 1, 32);
                    let sum = WarpBinOpShared(sData,laneId,cuda_popc_u32(mask) as u32 - 1u32);
                    
                    if laneId == 0u32 {
                        c.values(c.row_index(warpId) as i32 + currentCol as i32) = sum;
                        c.cols(c.row_index(warpId) as i32 + currentCol as i32) = frontColMin - 1u32;
                    }
                    
                    while_flag = if rowPos < b.row_index(bRowId + 1u32) {1} else {0};
                    while_loop = cuda_warp_sync_any(mask, while_flag) == 1;

                    currentCol = currentCol + 1u32;
                }

                
            }
        }
    }

    synchronize_cuda(0);


}

fn maxRowLength(a : &CSR) -> u32 {

    let mut maxRow = 0u32;

    for r in range(0,(*a).M as i32){
        if (*a).row_index(r+1) - (*a).row_index(r) > maxRow {
            maxRow = (*a).row_index(r+1) - (*a).row_index(r);
        }
    }

    return(maxRow)
}

fn spGEMMdecompose(a : CSR) -> (CSR,CSR) {

    let warpSize = 32;
    let mut new_rows = 0;

    for r in range(0,a.M as i32) {
        if a.row_index(r+1) - a.row_index(r) > warpSize as u32 {
            let mut rowStart = a.row_index(r);
            let mut rowEnd = a.row_index(r+1);
            while(rowStart < rowEnd) {
                    new_rows = new_rows + 1;
                    rowStart = rowStart + warpSize as u32;
            }
        } else {
            new_rows = new_rows + 1;
        }
    }

    let GCsrOffsets = alloc_cpu((new_rows + 1) as i64 * sizeof[u32]()).data as &mut[u32];
    GCsrOffsets(0) = 0u32;
    let GValues = alloc_cpu(a.nnz as i64 * sizeof[f32]()).data as &mut[f32];
    let GCols = alloc_cpu(a.nnz as i64 * sizeof[u32]()).data as &mut[u32];


    //copy values and cols to GCols and GValues

    runtime_copy(runtime_device(0, 0), a.cols as &[i8], 0i64, runtime_device(0, 0), GCols as &[i8], 0i64, (a.nnz) as i64 * sizeof[u32]()); // 4 or 1?
    runtime_copy(runtime_device(0, 0), a.values as &[i8], 0i64, runtime_device(0, 0), GValues as &[i8], 0i64, (a.nnz) as i64 * sizeof[u32]()); // 4 or 1?


    let A1CsrOffsets = alloc_cpu((a.M + 1u32) as i64 * sizeof[u32]()).data as &mut[u32];
    A1CsrOffsets(0) = 0u32;
    let A1Cols = alloc_cpu(new_rows as i64 * sizeof[u32]()).data as &mut[u32];
    let A1Values = alloc_cpu(new_rows as i64 * sizeof[f32]()).data as &mut[f32];
    

    let mut GRowIdx = 0; 
    let mut A1Col = 0u32;
    let mut A1Val = 0;

    for r in range(0,a.M as i32) {
        let row_length = a.row_index(r+1) - a.row_index(r);
        let mut A1_row_length = 0u32;
        if row_length > warpSize as u32 {

            let mut rowStart = a.row_index(r);
            let mut rowEnd = a.row_index(r+1);
            
            while(rowStart < rowEnd) {
                if rowStart + warpSize as u32 > rowEnd {
                    GCsrOffsets(GRowIdx + 1) = rowStart + row_length as u32 - (warpSize as u32 * A1_row_length);
                    rowStart = rowStart + warpSize as u32;
                } else {
                    rowStart = rowStart + warpSize as u32;
                    GCsrOffsets(GRowIdx + 1) = rowStart;
                }
                A1_row_length = A1_row_length + 1u32;
                A1Values(A1Val) = 1.0f32;
                A1Cols(A1Val) = A1Col;
                A1Col = A1Col + 1u32;
                
                A1Val = A1Val + 1;
                GRowIdx = GRowIdx + 1;
                    
            }

        } else {
            A1_row_length = 1u32;
            GCsrOffsets(GRowIdx + 1) = a.row_index(r+1);
            A1Values(A1Val) = 1.0f32;
            A1Cols(A1Val) = A1Col;
            
            A1Col = A1Col + 1u32;    
            A1Val = A1Val + 1;
            GRowIdx = GRowIdx + 1;
                
        }
        A1CsrOffsets(r+1) = A1CsrOffsets(r) + A1_row_length;
    }

    let csrG = CSR {N : a.N, M : new_rows as u32, nnz : a.nnz, values : GValues, cols : GCols, row_index : GCsrOffsets};
    let csrA1 = CSR {N : new_rows as u32, M : a.M, nnz : new_rows as u32, values : A1Values, cols : A1Cols, row_index : A1CsrOffsets};
    
    (csrA1,csrG)
}

extern
fn spGEMMimpala(a : &CSR, b : &CSR)  -> CSR {
    let warpSize = 32u32;

    let mut res : &CSR = 0 as &CSR;

    if maxRowLength(*a) <= warpSize 
    {
        res = &spGEMMsimple(a,b);
    }
    else {

        let (a1,g) = spGEMMdecompose(*a);
        // let (a2,g2) = spGEMMdecompose(a1);
        // let (a3,g3) = spGEMMdecompose(a2);

        let c = spGEMMsimple(&g,b); //need to free g
        release_csr_Host(&g);
        
        res = &spGEMMimpala(&a1,&c);
        release_csr_Host(&a1);
        release_csr_Host(&c);
    }

    return(*res)
}

extern
fn spGEMMsimple(a : &CSR, b : &CSR) -> CSR {
    
    let aDevice = CSR {N : (*a).N, M : (*a).M, nnz : (*a).nnz, values : alloc_cuda(0,(*a).nnz as i64 * sizeof[f32]()).data as &mut[f32], cols : alloc_cuda(0,(*a).nnz as i64 * sizeof[i32]()).data as &mut[u32], row_index : alloc_cuda(0,((*a).M + 1u32) as i64 * sizeof[i32]()).data as &mut[u32]};
    let bDevice = CSR {N : (*b).N, M : (*b).M, nnz : (*b).nnz, values : alloc_cuda(0,(*b).nnz as i64 * sizeof[f32]()).data as &mut[f32], cols : alloc_cuda(0,(*b).nnz as i64 * sizeof[i32]()).data as &mut[u32], row_index : alloc_cuda(0,((*b).M + 1u32) as i64 * sizeof[i32]()).data as &mut[u32]};
    //copy a to aDevice

    copy_csr_toDevice(a,&aDevice);
    copy_csr_toDevice(b,&bDevice);

    let cDeviceRows = alloc_cuda(0,((*a).M + 1u32) as i64 * sizeof[i32]());
    
    preprosessRows(aDevice,bDevice,cDeviceRows.data as &mut[u32]); 
    
    prefixSum(cDeviceRows.data as &mut[u32], (*a).M + 1u32);


    let cHostRows = alloc_cpu(((*a).M + 1u32) as i64 * sizeof[i32]());
    let cHostRowsData = cHostRows.data as &mut[u32];
    cHostRowsData(0) = 0u32;

    //copy rows to host
    runtime_copy(runtime_device(1, 0), cDeviceRows.data as &[i8], 4i64, runtime_device(0, 0), cHostRowsData as &[i8], 4i64, (aDevice.M) as i64 * sizeof[u32]()); // 4 or 1?

    let cNnz = cHostRowsData((*a).M); //handle zero


    if cNnz == 0u32 {
        let cHostValues = alloc_cpu(cNnz as i64 * sizeof[f32]());
        let cHostCols = alloc_cpu(cNnz as i64 * sizeof[f32]());
        let cHost = CSR {N : (*b).N, M : (*a).M, nnz : cNnz, values : cHostValues.data as &mut[f32], cols : cHostCols.data as &mut[u32], row_index : cHostRows.data as &mut[u32]};
        //free a,b, crows

        release_csr_Device(&aDevice);
        release_csr_Device(&bDevice);

        runtime_release(runtime_device(1, 0), cDeviceRows.data as &[i8]);    
        
        return (cHost)
    } else {
        let cDeviceCols = alloc_cuda(0,(cNnz as i64 * sizeof[i32]()));
        let cDeviceValues = alloc_cuda(0,(cNnz as i64 * sizeof[i32]()));
        
        let cDevice = CSR {N : (*b).N, M : (*a).M, nnz : cNnz, values : cDeviceValues.data as &mut[f32], cols : cDeviceCols.data as &mut[u32], row_index : cDeviceRows.data as &mut[u32]};
        
        
        spGEMMimpala_device(aDevice,bDevice,cDevice);

        let cHostValues = alloc_cpu(cNnz as i64 * sizeof[f32]());
        let cHostCols = alloc_cpu(cNnz as i64 * sizeof[f32]());

        let cHost = CSR {N : (*b).N, M : (*a).M, nnz : cNnz, values : cHostValues.data as &mut[f32], cols : cHostCols.data as &mut[u32], row_index : cHostRows.data as &mut[u32]};
        
        // copy_csr_toHost(&cDevice,&cHost);
        // copy c to host
        runtime_copy(runtime_device(1, 0), cDeviceValues.data as &[i8], 0i64, runtime_device(0, 0), cHostValues.data as &[i8], 0i64, (cNnz) as i64 * sizeof[f32]()); // 4 or 1?

        runtime_copy(runtime_device(1, 0), cDeviceCols.data as &[i8], 0i64, runtime_device(0, 0), cHostCols.data as &[i8], 0i64, (cNnz) as i64 * sizeof[u32]()); // 4 or 1?


        //release c
        runtime_release(runtime_device(1, 0), cDeviceValues.data as &[i8]);
        runtime_release(runtime_device(1, 0), cDeviceRows.data as &[i8]);
        runtime_release(runtime_device(1, 0), cDeviceCols.data as &[i8]);
        //cudaFree
        release_csr_Device(&aDevice);
        release_csr_Device(&bDevice);
        // release_csr_Device(&cDevice);
        
        return(cHost)    
    
    }

}
